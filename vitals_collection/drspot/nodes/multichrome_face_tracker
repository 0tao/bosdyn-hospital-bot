#!/usr/bin/env python

# Copyright 2020 Boston Dynamics Inc.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np
import cv2
import insightface

import rospy
from sensor_msgs.msg import Image
from geometry_msgs.msg import PolygonStamped, Point32
from std_msgs.msg import Bool
from cv_bridge import CvBridge

IMAGE_TOPIC = 'camera_array/mono_red/image_raw'
SCALED_IMAGE_TOPIC = 'debug_mono_red_tracking_rescale'
DEBUG_IMAGE_TOPIC = 'debug_mono_red_tracking'
CAROTID_REGION_TOPIC = 'carotid_roi'
TRACKING_STATUS_TOPIC = 'mono_red_tracking_status'
MAX_DROPOUT_BEFORE_RESET_SEC = 1.0
MAX_TIME_SINCE_DETECTION_SEC = 2.5

DETECT_TRACK_SCALE_FACTOR = 0.25

FACE_DETECTION_LIKELIHOOD_THRESHOLD = 0.7
MIN_FACE_DIM_PIXELS = 10
FACE_DETECTION_SCALE = 0.5
CV_TRACKER_TYPE = 'CSRT' #'KCF'

FACE_DETECTION_INTENSITY_RANGE = 150.0
FACE_DETECTION_INTENSITY_OFFSET = (255.0 - FACE_DETECTION_INTENSITY_RANGE) / 2.0

# Shift the mask ROI down from the detected landmarks.
CAROTID_HEIGHT_FRAC_OF_FACE_DOWN = 0.6
CAROTID_HALF_HEIGHT_FRAC_OF_FACE = 0.15
CAROTID_HALF_WIDTH_FRAC_OF_FACE = 0.25

ROS_THERMAL_IMAGE_BUFFER_SIZE = 640*480 * 2 * 3

class ROITracker(object):
    def __init__(self, tracker_type):
        self.ok = False
        self.bbox = np.array([0, 0, 0, 0])

        try:
            self.tracker = cv2.Tracker_create(tracker_type)
        except AttributeError:
            if tracker_type == 'BOOSTING':
                self.tracker = cv2.TrackerBoosting_create()
            if tracker_type == 'MIL':
                self.tracker = cv2.TrackerMIL_create()
            if tracker_type == 'KCF':
                self.tracker = cv2.TrackerKCF_create()
            if tracker_type == 'TLD':
                self.tracker = cv2.TrackerTLD_create()
            if tracker_type == 'MEDIANFLOW':
                self.tracker = cv2.TrackerMedianFlow_create()
            if tracker_type == 'GOTURN':
                self.tracker = cv2.TrackerGOTURN_create()
            if tracker_type == 'MOSSE':
                self.tracker = cv2.TrackerMOSSE_create()
            if tracker_type == 'CSRT':
                self.tracker = cv2.TrackerCSRT_create()

    def get_center(self):
        return np.array([(self.bbox[0] + self.bbox[2]) * 0.5,
                         (self.bbox[1] + self.bbox[3]) * 0.5])

    def start_track(self, frame, bbox):
        temp_bbox = (int(bbox[0]), int(bbox[1]), int(bbox[2] - bbox[0]), int(bbox[3] - bbox[1]))
        self.tracker.init(frame, temp_bbox)
        self.ok = True
        self.bbox = np.array(bbox)

    def update(self, frame):
        if not self.ok:
            return

        self.ok, temp_bbox = self.tracker.update(frame)
        self.bbox = np.array([temp_bbox[0], temp_bbox[1],
                              temp_bbox[0] + temp_bbox[2], temp_bbox[1] + temp_bbox[3]])

class FaceDetectorTracker(object):
    def image_callback(self, data):
        det_msg = Bool()
        det_msg.data = False
        t = data.header.stamp.to_sec()
        if self.tlast is None:
            self.tlast = t
            self.tracking_status_pub.publish(det_msg)
            return

        # Detect backward jumps in time in replay.
        if self.tlast > t:
            self.clear_msmt_state()
            self.tlast = t
            rospy.logwarn_throttle(1, '{}: Backward jump in time'.format(self.name))
            self.tracking_status_pub.publish(det_msg)
            return

        # Detect skips in data.
        if t - self.tlast > MAX_DROPOUT_BEFORE_RESET_SEC:
            rospy.logwarn_throttle(1, '{}: Dropped samples for {} sec'.format(self.name, t - self.tlast))
            self.clear_msmt_state()
            self.tlast = t
            self.tracking_status_pub.publish(det_msg)
            return

        self.tlast = t

        cv_image = self.bridge.imgmsg_to_cv2(data, desired_encoding='passthrough')
        (rows, cols) = cv_image.shape

        r = int(rows * DETECT_TRACK_SCALE_FACTOR)
        c = int(cols * DETECT_TRACK_SCALE_FACTOR)
        cv_image = cv2.resize(cv_image, (c, r), interpolation=cv2.INTER_AREA)

        imin = np.amin(cv_image)
        imax = np.amax(cv_image)
        irange = imax - imin
        if irange == 0:
            rospy.logwarn_throttle(1, '{}: Blank mono image'.format(self.name))
            self.tracking_status_pub.publish(det_msg)
            return
        #cv_image = ((cv_image - imin) * FACE_DETECTION_INTENSITY_RANGE / irange
        #            + FACE_DETECTION_INTENSITY_OFFSET).astype('uint8')

        msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='passthrough')
        self.scaled_image_pub.publish(msg)

        chan3image = cv2.cvtColor(cv_image, cv2.COLOR_GRAY2RGB)

        # If tracking is OK, track. Else, detect and configure tracker.
        bboxes = np.array([])
        landmarks = np.array([])
        fidx = 0
        self.carotid_tracker.update(chan3image)
        if self.carotid_tracker.ok and self.tlast_detection is not None and t - self.tlast_detection < MAX_TIME_SINCE_DETECTION_SEC:
            carotid = self.carotid_tracker.bbox.reshape((2, 2))
        else:
            rospy.loginfo_throttle(1, '{}: Lost tracking; running face detector'.format(self.name))
            self.carotid_tracker = ROITracker(CV_TRACKER_TYPE)
            bboxes, landmarks = self.detector.detect(chan3image,
                                                     threshold=FACE_DETECTION_LIKELIHOOD_THRESHOLD,
                                                     scale=FACE_DETECTION_SCALE)

            if len(bboxes) == 0:
                self.tracking_status_pub.publish(det_msg)
                rospy.logwarn_throttle(1, '{}: no faces detected'.format(self.name))
                self.clear_msmt_state()
                return

            # TODO - If we select a specific face, re-order so that face is first (index 0).
            if len(bboxes) > 1:
                rospy.logwarn_throttle(1, '{}: {} faces detected; picking the first'.format(self.name, len(bboxes)))

            wface = bboxes[fidx][2] - bboxes[fidx][0]
            hface = bboxes[fidx][3] - bboxes[fidx][1]
            if (wface < MIN_FACE_DIM_PIXELS) or (hface < MIN_FACE_DIM_PIXELS):
                self.tracking_status_pub.publish(det_msg)
                rospy.logwarn_throttle(1, '{}: face too small'.format(self.name))
                self.clear_msmt_state()
                return

            det_msg.data = True
            self.tracking_status_pub.publish(det_msg)
            self.tlast_detection = t

            lmouth = landmarks[fidx][3]
            rmouth = landmarks[fidx][4]
            midcarotid = np.array([0.0, 0.0])
            # Unlike the mask and eye region, this should move with the face bbox, not the landmarks.
            midcarotid[0] = 0.5 * (bboxes[fidx][2] + bboxes[fidx][0])
            midcarotid[1] = 0.5 * (lmouth[1] + rmouth[1]) + hface * CAROTID_HEIGHT_FRAC_OF_FACE_DOWN
            half_wcarotid = wface * CAROTID_HALF_WIDTH_FRAC_OF_FACE
            half_hcarotid = hface * CAROTID_HALF_HEIGHT_FRAC_OF_FACE
            carotid = midcarotid + np.array([[-half_wcarotid, -half_hcarotid], [half_wcarotid, half_hcarotid]])
            self.carotid_tracker.start_track(chan3image, carotid.reshape((4)))

        region = PolygonStamped()
        region.header = data.header
        carotid_unscaled = carotid / DETECT_TRACK_SCALE_FACTOR
        region.polygon.points = [Point32(x=carotid_unscaled[0][0], y=carotid_unscaled[0][1], z=0),
                                 Point32(x=carotid_unscaled[1][0], y=carotid_unscaled[1][1], z=0)]
        self.carotid_region_pub.publish(region)

        # All overlays have colors below in case we use an RGB image in the future.
        for box in bboxes.astype(int):
            x, y, x2, y2 = box[0:4]
            # Draw a rectangle for each face bounding box.
            cv2.rectangle(cv_image, (x, y), (x2, y2), (0,0,255), 1)
        for face in landmarks.astype(int):
            for point in face:
                x, y = point
                # Draw a circle at each landmark.
                cv2.circle(cv_image, (x, y), 5, (0,0,255), 1)

        carotid = carotid.astype(int)
        cv2.rectangle(cv_image, tuple(carotid[0].tolist()), tuple(carotid[1].tolist()), (255,0,0), 2)

        msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='passthrough')
        self.debug_image_pub.publish(msg)

    def clear_msmt_state(self):
        rospy.logwarn_throttle(1, '{}: Resetting'.format(self.name))
        self.carotid_tracker.ok = False
        self.tlast = None
        self.tlast_detection = None

    def __init__(self, name):
        self.name = name

        self.bridge = CvBridge()

        self.detector = insightface.model_zoo.get_model('retinaface_r50_v1')
        self.detector.prepare(ctx_id=-1, nms=0.4)

        self.carotid_tracker = ROITracker(CV_TRACKER_TYPE)

        self.clear_msmt_state()

        self.carotid_region_pub = rospy.Publisher(CAROTID_REGION_TOPIC, PolygonStamped, queue_size=10)

        self.debug_image_pub = rospy.Publisher(DEBUG_IMAGE_TOPIC, Image, queue_size=10)
        self.scaled_image_pub = rospy.Publisher(SCALED_IMAGE_TOPIC, Image, queue_size=10)

        self.tracking_status_pub = rospy.Publisher(TRACKING_STATUS_TOPIC, Bool, queue_size=10)

        self.image_sub = rospy.Subscriber(IMAGE_TOPIC, Image, self.image_callback, queue_size=1, buff_size=ROS_THERMAL_IMAGE_BUFFER_SIZE)

if __name__ == '__main__':
    rospy.init_node('ir_face_tracker')
    resp = FaceDetectorTracker(rospy.get_name())
    rospy.spin()
