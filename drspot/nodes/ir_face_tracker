#!/usr/bin/env python

# Copyright 2020 Boston Dynamics Inc.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np
import cv2
import insightface

import rospy
from sensor_msgs.msg import Image
from geometry_msgs.msg import PolygonStamped, Point32
from std_msgs.msg import Bool
from cv_bridge import CvBridge

IMAGE_TOPIC = 'thermal_image_raw'
SCALED_IMAGE_TOPIC = 'debug_thermal_tracking_rescale'
DEBUG_IMAGE_TOPIC = 'debug_thermal_tracking'
EYE_REGION_TOPIC = 'skin_temp_roi'
MASK_REGION_TOPIC = 'mask_roi'
TRACKING_STATUS_TOPIC = 'tracking_status'
MAX_DROPOUT_BEFORE_RESET_SEC = 0.2

FACE_DETECTION_LIKELIHOOD_THRESHOLD = 0.5
MIN_FACE_DIM_PIXELS = 10
FACE_DETECTION_SCALE = 1.5

FACE_DETECTION_INTENSITY_RANGE = 150.0
FACE_DETECTION_INTENSITY_OFFSET = (255.0 - FACE_DETECTION_INTENSITY_RANGE) / 2.0

EYE_HALF_HEIGHT_FRAC_OF_FACE = 1.0 / 10.0
EYE_HALF_WIDTH_FRAC_OF_FACE = 0.45

MASK_HALF_HEIGHT_FRAC_OF_FACE = 0.15
MASK_HALF_WIDTH_FRAC_OF_FACE = 0.25

ROS_THERMAL_IMAGE_BUFFER_SIZE = 640*480 * 2 * 3

class FaceDetectorTracker(object):
    def image_callback(self, data):
        cv_image = self.bridge.imgmsg_to_cv2(data, desired_encoding='passthrough')
        imin = np.amin(cv_image)
        imax = np.amax(cv_image)
        irange = imax - imin
        if irange == 0:
            rospy.logwarn_throttle(1, 'Blank IR image')
            return
        cv_image = ((cv_image - imin) * FACE_DETECTION_INTENSITY_RANGE / irange + FACE_DETECTION_INTENSITY_OFFSET).astype('uint8')

        msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='passthrough')
        self.scaled_image_pub.publish(msg)

        chan3image = cv2.cvtColor(cv_image, cv2.COLOR_GRAY2RGB)
        bboxes, landmarks = self.detector.detect(chan3image, threshold=FACE_DETECTION_LIKELIHOOD_THRESHOLD,
                                                 scale=FACE_DETECTION_SCALE)
        if len(bboxes) > 1:
            rospy.logwarn_throttle(1, '{} faces detected; picking the first'.format(len(bboxes)))

        det_msg = Bool()
        det_msg.data = False
        if len(bboxes) == 0:
            self.tracking_status_pub.publish(det_msg)
            rospy.logwarn_throttle(1, 'no faces detected')
            return

        fidx = 0
        wface = bboxes[fidx][2] - bboxes[fidx][0]
        hface = bboxes[fidx][3] - bboxes[fidx][1]
        if (wface < MIN_FACE_DIM_PIXELS) or (hface < MIN_FACE_DIM_PIXELS):
            self.tracking_status_pub.publish(det_msg)
            rospy.logwarn_throttle(1, 'no faces detected')
            return

        det_msg.data = True
        self.tracking_status_pub.publish(det_msg)

        region = PolygonStamped()
        region.header = data.header

        leye = landmarks[fidx][0]
        reye = landmarks[fidx][1]
        mideye = 0.5 * (np.array(leye) + np.array(reye))
        half_weye = max(abs(leye[0] - mideye[0]), wface * EYE_HALF_WIDTH_FRAC_OF_FACE)
        half_heye = max(abs(leye[1] - mideye[1]), hface * EYE_HALF_HEIGHT_FRAC_OF_FACE)
        eye = mideye + np.array([[-half_weye, -half_heye], [half_weye, half_heye]])
        region.polygon.points = [Point32(x=eye[0][0], y=eye[0][1], z=0),
                                 Point32(x=eye[1][0], y=eye[1][1], z=0)]
        self.eye_region_pub.publish(region)
        lmouth = landmarks[fidx][3]
        rmouth = landmarks[fidx][4]
        midmouth = 0.5 * (np.array(lmouth) + np.array(rmouth))
        half_wmouth = max(abs(lmouth[0] - midmouth[0]), wface * MASK_HALF_WIDTH_FRAC_OF_FACE)
        half_hmouth = max(abs(lmouth[1] - midmouth[1]), hface * MASK_HALF_HEIGHT_FRAC_OF_FACE)
        mouth = midmouth + np.array([[-half_wmouth, -half_hmouth], [half_wmouth, half_hmouth]])
        region.polygon.points = [Point32(x=mouth[0][0], y=mouth[0][1], z=0),
                                 Point32(x=mouth[1][0], y=mouth[1][1], z=0)]
        self.mask_region_pub.publish(region)

        # All overlays have colors below in case we use an RGB image in the future.
        for box in bboxes.astype(int):
            x, y, x2, y2, conf = box
            # Draw a rectangle for each face bounding box.
            cv2.rectangle(cv_image, (x, y), (x2, y2), (0,0,255), 1)
        for face in landmarks.astype(int):
            for point in face:
                x, y = point
                # Draw a circle at each landmark.
                cv2.circle(cv_image, (x, y), 5, (0,255,0), 1)

        eye = eye.astype(int)
        cv2.rectangle(cv_image, tuple(eye[0].tolist()), tuple(eye[1].tolist()), (255,0,0), 2)
        mouth = mouth.astype(int)
        cv2.rectangle(cv_image, tuple(mouth[0].tolist()), tuple(mouth[1].tolist()), (255,0,0), 2)

        msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='passthrough')
        self.debug_image_pub.publish(msg)

    def __init__(self, name):
        self.name = name

        self.bridge = CvBridge()

        self.detector = insightface.model_zoo.get_model('retinaface_r50_v1')
        self.detector.prepare(ctx_id=-1, nms=0.4)

        self.eye_region_pub = rospy.Publisher(EYE_REGION_TOPIC, PolygonStamped, queue_size=10)
        self.mask_region_pub = rospy.Publisher(MASK_REGION_TOPIC, PolygonStamped, queue_size=10)

        self.debug_image_pub = rospy.Publisher(DEBUG_IMAGE_TOPIC, Image, queue_size=10)
        self.scaled_image_pub = rospy.Publisher(SCALED_IMAGE_TOPIC, Image, queue_size=10)

        self.tracking_status_pub = rospy.Publisher(TRACKING_STATUS_TOPIC, Bool, queue_size=10)

        self.image_sub = rospy.Subscriber(IMAGE_TOPIC, Image, self.image_callback, queue_size=1, buff_size=ROS_THERMAL_IMAGE_BUFFER_SIZE)

if __name__ == '__main__':
    rospy.init_node('ir_face_tracker')
    resp = FaceDetectorTracker(rospy.get_name())
    rospy.spin()
